# -*- coding: utf-8 -*-
"""
sentiment_stance_weibo.py
Step 3 : æƒ…æ„Ÿ + ç«‹åœºåˆ†æï¼ˆå¾®åšï¼‰
-----------------------------------------------
è¾“å…¥ : weibo_cleaned.csv  (åŒ…å« clean_text åˆ—)
è¾“å‡º :
  weibo_sent_binary.csv   # neg_prob / pos_prob
  weibo_sent_emotion.csv  # 8-emotion æ¦‚ç‡ (joy/anger/â€¦/fear)
  weibo_stance.csv        # entail / neutral / contradict æ¦‚ç‡
"""

import warnings, os, sys
warnings.filterwarnings("ignore")

from pathlib import Path
import pandas as pd
from tqdm import tqdm
import torch, numpy as np
import torch.nn.functional as F
from transformers import (
    pipeline,
    AutoTokenizer,
    AutoModelForSequenceClassification,
)

# ------------------------------------------------------------
# 0. è¯»å…¥é¢„å¤„ç†å¾®åš
# ------------------------------------------------------------
# è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
SCRIPT_DIR = Path(__file__).parent
DATA_DIR = SCRIPT_DIR.parent / 'data'
OUTPUT_DIR = DATA_DIR / 'outputs'
OUTPUT_DIR.mkdir(exist_ok=True, parents=True)
CSV_FILE = DATA_DIR / "weibo_cleaned.csv"
assert CSV_FILE.exists(), f"æ‰¾ä¸åˆ° {CSV_FILE}"

df = pd.read_csv(CSV_FILE)
df["clean_text"] = df["clean_text"].fillna("")
texts = df["clean_text"].tolist()
print(f"æ ·æœ¬é‡ï¼š{len(df):,}")

DEVICE = 0 if torch.cuda.is_available() else -1   # GPU id or CPU

########################################################################
# 1. äºŒåˆ†ç±»æƒ…æ„Ÿ Positive / Negative
########################################################################
print("\nğŸŸ¢ Step 1 | Binary Sentiment (Pos/Neg)")

bin_model = "uer/roberta-base-finetuned-jd-binary-chinese"
sent_bin = pipeline(
    "sentiment-analysis",
    model=bin_model,
    tokenizer=bin_model,
    device=DEVICE,
    truncation=True,
    max_length=128,
)

neg_prob, pos_prob = [], []
for out in tqdm(sent_bin(texts, batch_size=32), total=len(df)):
    if out["label"].lower().startswith("pos"):
        pos_prob.append(out["score"])
        neg_prob.append(1 - out["score"])
    else:
        neg_prob.append(out["score"])
        pos_prob.append(1 - out["score"])

df_bin = df.copy()
df_bin["neg_prob"] = neg_prob
df_bin["pos_prob"] = pos_prob
df_bin.to_csv(OUTPUT_DIR / "weibo_sent_binary.csv", index=False, encoding='utf-8')
print("âœ… Binary æƒ…æ„Ÿç»“æœå·²å†™å…¥ weibo_sent_binary.csv")

########################################################################
# 2. å…«ç±»æƒ…ç»ª (Joy / Anger / Fear / â€¦)
########################################################################
print("\nğŸŸ¢ Step 2 | 8-Class Emotion")

emo_model = "Johnson8187/Chinese-Emotion"   # é¢„è®­ç»ƒ 8 ç±»æƒ…ç»ª
emo_pipe = pipeline(
    "text-classification",
    model=emo_model,
    tokenizer=emo_model,
    device=DEVICE,
    top_k=None,
    truncation=True,
    max_length=128,
)

# Emotion æ ‡ç­¾é¡ºåºä»¥æ¨¡å‹ config.json é‡Œçš„ id2label ä¸ºå‡†
emo_labels = emo_pipe.model.config.id2label.values()  # ä¿è¯é¡ºåº
emo_columns = [f"emo_{lbl.lower()}" for lbl in emo_labels]

prob_mat = np.zeros((len(df), len(emo_labels)), dtype=np.float32)
for i, outs in enumerate(tqdm(emo_pipe(texts, batch_size=32),
                              total=len(df))):
    for out in outs:                        # outs æ˜¯ list[dict]
        idx = list(emo_labels).index(out["label"])
        prob_mat[i, idx] = out["score"]

df_emo = pd.concat([df, pd.DataFrame(prob_mat, columns=emo_columns)], axis=1)
df_emo.to_csv(OUTPUT_DIR / "weibo_sent_emotion.csv", index=False, encoding='utf-8')
print("âœ… 8-æƒ…ç»ªæ¦‚ç‡å·²å†™å…¥ weibo_sent_emotion.csv")

########################################################################
# 3. ç«‹åœºåˆ¤å®š (æ”¯æŒ / åå¯¹ / ä¸­ç«‹) â€”â€” NLI é›¶æ ·æœ¬
########################################################################
print("\nğŸŸ¢ Step 3 | Stance Zero-Shot (Entail / Neutral / Contradict)")

stance_model_name = "IDEA-CCNL/Erlangshen-Roberta-110M-NLI"
tok_stance = AutoTokenizer.from_pretrained(stance_model_name)
mdl_stance = AutoModelForSequenceClassification.from_pretrained(
    stance_model_name
).to(torch.device("cuda" if DEVICE >= 0 else "cpu")).eval()

# å®šä¹‰è®®é¢˜ & æ„é€  hypothesis
TOPIC_CN = "æå©šæˆ–æè‚²"
HYP_ENTAIL = f"è¿™æ¡å¾®åšæ”¯æŒ{TOPIC_CN}"
HYP_CONTRA = f"è¿™æ¡å¾®åšåå¯¹{TOPIC_CN}"

batch = 16
entail_p, neut_p, contra_p = [], [], []

with torch.no_grad():
    for i in tqdm(range(0, len(df), batch), desc="stance infer"):
        premise_batch = texts[i:i+batch]

        # åˆ†åˆ«ä¸ä¸¤ä¸ªå‡è®¾åš NLI
        inputs_yes = tok_stance(premise_batch, [HYP_ENTAIL]*len(premise_batch),
                                padding=True, truncation=True,
                                max_length=128, return_tensors="pt")
        inputs_no  = tok_stance(premise_batch, [HYP_CONTRA]*len(premise_batch),
                                padding=True, truncation=True,
                                max_length=128, return_tensors="pt")

        inputs_yes = {k:v.to(mdl_stance.device) for k,v in inputs_yes.items()}
        inputs_no  = {k:v.to(mdl_stance.device) for k,v in inputs_no.items()}

        logit_yes = mdl_stance(**inputs_yes).logits          # [B,3]
        logit_no  = mdl_stance(**inputs_no).logits

        prob_yes = F.softmax(logit_yes, dim=-1).cpu().numpy()
        prob_no  = F.softmax(logit_no,  dim=-1).cpu().numpy()

        # é‡‡ç”¨ Yes-Entail æ¦‚ç‡ä½œä¸º"æ”¯æŒ"ï¼ŒNo-Contradict ä½œä¸º"åå¯¹" (ç®€åŒ–)
        entail_p.extend(prob_yes[:, 0])       # entail
        neut_p.extend((prob_yes[:, 1] + prob_no[:, 1]) / 2)  # neutral
        contra_p.extend(prob_no[:, 0])        # entail (åå¯¹å‘½é¢˜)

df_stance = df.copy()
df_stance["stance_entail"] = entail_p
df_stance["stance_neutral"] = neut_p
df_stance["stance_contra"] = contra_p
df_stance.to_csv(OUTPUT_DIR / "weibo_stance.csv", index=False, encoding='utf-8')
print("âœ… ç«‹åœºæ¦‚ç‡å·²å†™å…¥ weibo_stance.csv")

print("\nğŸ‰ å…¨éƒ¨å®Œæˆï¼ç»“æœæ–‡ä»¶ï¼š")
print("  â€¢ weibo_sent_binary.csv")
print("  â€¢ weibo_sent_emotion.csv")
print("  â€¢ weibo_stance.csv")
